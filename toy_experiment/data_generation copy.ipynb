{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Otimização - Toy Experiment: Mitigação de Crosstalk**\n",
    "\n",
    "**Disciplina:** PPGEE0016 - Otimização\n",
    "\n",
    "**Alunos:** André Paiva, Josias Souza, Victor Emanuel Paz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../crosstalk/\")\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functions import *\n",
    "from XTconstants import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a random seed for reproducibility. Using a fixed seed value (5) ensures that the random numbers generated\n",
    "# are the same across different runs of the code. This is important for verifying results, as it allows\n",
    "# for consistent experimentation and comparison of outcomes.\n",
    "#np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_s(params, n, sampling_period=25):\n",
    "    \"\"\"\n",
    "    Function to approximate samples from signal contaminated by crosstalk.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ``params``: Dictionary containing E, tau, E_x, tau_x.\n",
    "    ``n``: Sample index.\n",
    "    ``sampling_period``: Time distance between samples (default is 25ns).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Value from sample of approximated function according to given parameters.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    clean_signal = params[\"E\"]*cellFunction(sampling_period*(n+1) + params[\"tau\"])\n",
    "    xt_signal = params[\"E_x\"]*XTalk(sampling_period*(n+1) + params[\"tau_x\"])\n",
    "    return clean_signal + xt_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_mse(samples, params, sampling_period=25):\n",
    "    mse = 0\n",
    "    for i in range(samples.shape[0]):\n",
    "        mse += (samples[i] - func_s(params, i, sampling_period))**2\n",
    "    mse /= samples.shape[0]\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"E\": 50000, \"tau\": 0, \"E_x\": 200, \"tau_x\": 0}\n",
    "func = [func_s(params, i) for i in range(4)]\n",
    "plt.plot(func, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição aleatória para Tau\n",
    "\n",
    "#teste_aleatorio = np.abs(np.random.normal(loc=5, scale=5, size=100000))\n",
    "teste_aleatorio =  np.random.normal(loc=47, scale=1.75, size=100000)\n",
    "#teste_aleatorio =  np.abs(np.random.normal(loc=9000, scale=8000, size=100000))\n",
    "teste_aleatorio.shape\n",
    "sns.histplot(teste_aleatorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetico(samples, funcao=func_mse, sampling_period=25, populacao=100, iteracoes=50, p_recomb=0.15, p_mutacao = 0.05):\n",
    "    E_init = np.abs(np.random.normal(loc=90000, scale=80000, size=populacao))\n",
    "    tau_init = np.abs(np.random.normal(loc=5, scale=10, size=populacao))\n",
    "    E_x_init = np.abs(np.random.normal(loc=9000, scale=8000, size=populacao))\n",
    "    tau_x_init = np.abs(np.random.normal(loc=5, scale=10, size=populacao))\n",
    "    x_matrix = np.stack([E_init, tau_init, E_x_init, tau_x_init], axis=1)\n",
    "    avg_fitness = np.array([])\n",
    "    min_fitness = np.array([])\n",
    "    col = ['E', 'tau', 'E_x', 'tau_x', 'fitness', 'iter']\n",
    "    df_evolution = pd.DataFrame(columns=col)\n",
    "    x_pop = np.copy(x_matrix)\n",
    "    time_init = time()\n",
    "    best = {\"E\" : -np.inf, \"tau\": -np.inf, \"E_x\": -np.inf, \"tau_x\": -np.inf}\n",
    "    for i in range(iteracoes):\n",
    "        # Cálculo de Fitness e inserção no dataframe\n",
    "        x_params = [{\"E\": candidato[0],\n",
    "                     \"tau\": candidato[1],\n",
    "                     \"E_x\": candidato[2],\n",
    "                     \"tau_x\": candidato[3]} for candidato in x_pop]\n",
    "        x_fitness = np.array([-funcao(samples, params, sampling_period) for params in x_params]).reshape(-1, 1)\n",
    "        iter_atual = np.tile([i], x_matrix.shape[0]).reshape(-1, 1)\n",
    "        df_data = np.concatenate((x_pop, x_fitness, iter_atual), axis=1)\n",
    "        df_evolution = pd.concat([df_evolution, pd.DataFrame(df_data, columns=col)]).reset_index(drop=True)\n",
    "        # Captura de fitness médio e fitness mínimo por iteração\n",
    "        avg_fitness = np.append(avg_fitness, np.mean(x_fitness))\n",
    "        min_fitness = np.append(min_fitness, np.min(x_fitness))\n",
    "        # Sorting Crescente\n",
    "        x_sort = np.argsort(x_fitness, axis=0).reshape(-1)\n",
    "        x_fitness = x_fitness[x_sort]\n",
    "        x_pop = x_pop[x_sort]\n",
    "        best = {\"E\" : x_pop[x_pop.shape[0]-1, 0],\n",
    "                \"tau\": x_pop[x_pop.shape[0]-1, 1],\n",
    "                \"E_x\": x_pop[x_pop.shape[0]-1, 2],\n",
    "                \"tau_x\": x_pop[x_pop.shape[0]-1, 3]}\n",
    "        # Cálculo de probabilidades de seleção\n",
    "        prob_num = np.array([np.sum(np.arange(1, i+1)) for i in range(1, x_matrix.shape[0]+1)])\n",
    "        prob_den = np.sum(np.arange(1, x_fitness.shape[0]+1))\n",
    "        prob = prob_num/prob_den\n",
    "        # Seleção de elementos\n",
    "        selecao_prob = np.random.rand(np.ceil(x_fitness.shape[0]/2).astype(np.int32), 2)\n",
    "        index_selecao_prob = np.searchsorted(prob, selecao_prob, side='right')\n",
    "        # Recombinação\n",
    "        new_pop = np.empty((0, x_pop.shape[1]))\n",
    "        for j in index_selecao_prob:\n",
    "            candidato1 = x_pop[j[0]]\n",
    "            candidato2 = x_pop[j[1]]\n",
    "            recomb_mask = np.random.rand(candidato1.shape[0])\n",
    "            recomb_mask = np.array([p <= p_recomb for p in recomb_mask])\n",
    "            novo_candidato1 = np.copy(candidato1)\n",
    "            np.putmask(novo_candidato1, recomb_mask, candidato2)\n",
    "            novo_candidato1 = novo_candidato1.reshape((1, -1))\n",
    "            novo_candidato2 = np.copy(candidato2)\n",
    "            np.putmask(novo_candidato2, recomb_mask, candidato1)\n",
    "            novo_candidato2 = novo_candidato2.reshape((1, -1))\n",
    "            new_pop = np.concatenate((new_pop, novo_candidato1, novo_candidato2), axis=0)\n",
    "        new_pop = new_pop[:x_pop.shape[0]]\n",
    "        # Mutação\n",
    "        E_init = np.abs(np.random.normal(loc=90000, scale=80000, size=populacao))\n",
    "        tau_init = np.abs(np.random.normal(loc=5, scale=10, size=populacao))\n",
    "        E_x_init = np.abs(np.random.normal(loc=9000, scale=8000, size=populacao))\n",
    "        tau_x_init = np.abs(np.random.normal(loc=5, scale=10, size=populacao))\n",
    "        mut_gen = np.stack([E_init, tau_init, E_x_init, tau_x_init], axis=1)\n",
    "        mut_mask = np.random.rand(new_pop.shape[0], new_pop.shape[1])\n",
    "        mut_mask = np.array([p <= p_mutacao for p in mut_mask])\n",
    "        np.putmask(new_pop, mut_mask, mut_gen)\n",
    "        # Nova População\n",
    "        x_pop = np.copy(new_pop)\n",
    "        if(i == iteracoes - 1):\n",
    "             # Cálculo de Fitness e inserção no dataframe\n",
    "            x_params = [{\"E\": candidato[0],\n",
    "                         \"tau\": candidato[1],\n",
    "                         \"E_x\": candidato[2],\n",
    "                         \"tau_x\": candidato[3]} for candidato in x_pop]\n",
    "            x_fitness = np.array([-funcao(samples, params, sampling_period) for params in x_params]).reshape(-1, 1)\n",
    "            iter_atual = np.tile([i], x_matrix.shape[0]).reshape(-1, 1)\n",
    "            df_data = np.concatenate((x_pop, x_fitness, iter_atual), axis=1)\n",
    "            df_evolution = pd.concat([df_evolution, pd.DataFrame(df_data, columns=col)]).reset_index(drop=True)\n",
    "            # Captura de fitness médio e fitness mínimo por iteração\n",
    "            avg_fitness = np.append(avg_fitness, np.mean(x_fitness))\n",
    "            min_fitness = np.append(min_fitness, np.min(x_fitness))\n",
    "\n",
    "    elapsed_time = (time() - time_init) * 1000\n",
    "    fitness_metrics = np.concatenate(([avg_fitness], [min_fitness]), axis = 0).transpose()\n",
    "    df_fitness = pd.DataFrame(fitness_metrics)\n",
    "    #df_fitness['Aptidao'] = ['Media', 'Minima']\n",
    "        \n",
    "    return best, df_evolution, df_fitness, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source   = '../crosstalk'                                              \n",
    "emsData  = f'{source}/clusters'\n",
    "\n",
    "fileEtrue  = glob.glob(f'{emsData}/*Etrue*.pkl')[0]\n",
    "fileXTc    = glob.glob(f'{emsData}/*XTc*.pkl')[0]\n",
    "fileXTl    = glob.glob(f'{emsData}/*XTl*.pkl')[0]\n",
    "\n",
    "EtrueAmp   = loadSaveDict( fileEtrue, load=True )\n",
    "XTcAmp     = loadSaveDict( fileXTc, load=True )\n",
    "XTlAmp     = loadSaveDict( fileXTl, load=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_amount = 100\n",
    "vectDelays = getIdxClus_mxn(cellsDelay, 7, 5)\n",
    "nSamp = 4\n",
    "tau_Etrue = np.abs(np.random.normal(loc=5, scale=5, size=signals_amount))\n",
    "tau_XT = tau_Etrue + np.abs(np.random.normal(loc=5, scale=5, size=signals_amount))\n",
    "\n",
    "Etrue_samp = np.array([])\n",
    "XTc_samp = np.array([])\n",
    "XTl_samp = np.array([])\n",
    "\n",
    "for i in range(signals_amount):\n",
    "    Etrue_samp = np.append(Etrue_samp, genCellSamples(vectDelays, tau_Etrue[i], nSamp)*(np.repeat(EtrueAmp[i].reshape(1, 25), nSamp, axis=1)))\n",
    "    XTc_samp = np.append(XTc_samp, genXTcSamples(vectDelays, tau_XT[i], nSamp)*(np.repeat(XTcAmp[i].reshape(1, 25), nSamp, axis=1)))\n",
    "    XTl_samp = np.append(XTl_samp, genXTlSamples(vectDelays, tau_XT[i], nSamp)*(np.repeat(XTlAmp[i].reshape(1, 25), nSamp, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_XTcl = Etrue_samp + XTc_samp + XTl_samp\n",
    "E_XTcl = E_XTcl.reshape(signals_amount, 25, -1)\n",
    "E_XTcl_center = E_XTcl[:100, 12, :]\n",
    "E_XTcl_center.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "best, df_evolution, df_fitness, elapsed_time = genetico(E_XTcl_center[index].reshape(-1))\n",
    "\n",
    "df_fitness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df_evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_est_comparison = pd.DataFrame(data=[[\"E\", best[\"E\"], EtrueAmp[index, 12]],\n",
    "                                 [\"Tau\", best[\"tau\"], tau_Etrue[index]],\n",
    "                                 [\"E_x\", best[\"E_x\"], XTcAmp[index, 12]+XTlAmp[index, 12]],\n",
    "                                 [\"Tau_x\", best[\"tau_x\"], tau_XT[index]]],\n",
    "                                 columns=[\"Parâmetro\", \"Estimado\", \"Esperado\"])\n",
    "\n",
    "df_est_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([best[\"tau\"] + 25,\n",
    "          best[\"tau\"] + 50,\n",
    "          best[\"tau\"] + 75,\n",
    "          best[\"tau\"] + 100], E_XTcl_center[1].reshape(-1), marker='o')\n",
    "\n",
    "tau_int = int(best[\"tau\"])\n",
    "tau_x_int = int(best[\"tau_x\"])\n",
    "\n",
    "ETrue_est = np.append(np.repeat([0], tau_int), [best[\"E\"]*cellFunction(t) for t in range(600 - tau_int)])\n",
    "XT_est = np.append(np.repeat([0], tau_x_int), [best[\"E_x\"]*XTalk(t) for t in range(600 - tau_x_int)])\n",
    "\n",
    "signal_est = ETrue_est + XT_est\n",
    "\n",
    "plt.plot(range(600), signal_est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
