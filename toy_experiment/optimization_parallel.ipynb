{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Otimização - Toy Experiment: Mitigação de Crosstalk**\n",
    "## **Notebook de Otimização**\n",
    "\n",
    "**Disciplina:** PPGEE0016 - Otimização\n",
    "\n",
    "**Alunos:** André Paiva, Josias Souza, Victor Emanuel Paz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../crosstalk/\")\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rc\n",
    "import seaborn as sns\n",
    "\n",
    "from functions import *\n",
    "from XTconstants import *\n",
    "\n",
    "sns.set_context(\"paper\", font_scale=2.0)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a random seed for reproducibility. Using a fixed seed value (5) ensures that the random numbers generated\n",
    "# are the same across different runs of the code. This is important for verifying results, as it allows\n",
    "# for consistent experimentation and comparison of outcomes.\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/data.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_s(params, n_samples=4, sampling_period=25):\n",
    "    \"\"\"\n",
    "    Function to approximate samples from signal contaminated by crosstalk.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ``params``: Array of dictionaries containing E, tau, E_x, tau_x.\n",
    "    ``n_samples``: Number of samples (default is 4).\n",
    "    ``sampling_period``: Time distance between samples (default is 25ns).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Value from sample of approximated function according to given parameters.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    clean_signal = np.array([params[i][\"E\"]*np.array(\n",
    "                        [cellFunction(sampling_period*(j+1)*46.74/params[i][\"tau\"] + params[i][\"sample_delay\"]) for j in range(n_samples)]\n",
    "                    ) for i in range(len(params))])\n",
    "    xt_signal = np.array([params[i][\"E_x\"]*np.array(\n",
    "                        [XTalk(sampling_period*(j+1)*32.16/params[i][\"tau_x\"] + params[i][\"sample_delay\"]) for j in range(n_samples)]\n",
    "                    ) for i in range(len(params))])\n",
    "    return clean_signal + xt_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_mse(signals_df, params, populacao, n_samples=4):\n",
    "    func_signals = func_s(params, n_samples=n_samples, sampling_period=signals_df[\"sampling_period\"][0])\n",
    "    samples = np.array([signals_df[f\"S_{i}\"] for i in range(1, n_samples+1)]).T\n",
    "    func_signals_matrix = np.array([func_signals for i in range(samples.shape[0])])\n",
    "    samples_matrix = np.transpose(np.array([samples for i in range(populacao)]), (1, 0, 2))\n",
    "    square_error = (samples_matrix - func_signals_matrix)**2\n",
    "    mse_matrix = np.sum(square_error, axis=2)/square_error.shape[2]\n",
    "    return mse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetico(signals_df, funcao=func_mse, populacao=50, iteracoes=30, p_recomb=0.3, p_mutacao = 0.15):\n",
    "    E_init = np.abs(np.random.normal(loc=90000, scale=80000, size=populacao))\n",
    "    tau_init = np.abs(np.random.normal(loc=60, scale=10, size=populacao))\n",
    "    E_x_init = np.abs(np.random.normal(loc=9000, scale=8000, size=populacao))\n",
    "    tau_x_init = np.abs(np.random.normal(loc=60, scale=10, size=populacao))\n",
    "    samp_delay_init = np.abs(np.random.normal(loc=3, scale=4, size=populacao))\n",
    "    x_matrix = np.stack([E_init, tau_init, E_x_init, tau_x_init, samp_delay_init], axis=1)\n",
    "    avg_fitness = np.array([])\n",
    "    min_fitness = np.array([])\n",
    "    col = ['E', 'tau', 'E_x', 'tau_x', 'sample_delay', 'fitness', 'iter']\n",
    "    df_evolution = pd.DataFrame(columns=col)\n",
    "    x_pop = np.copy(x_matrix)\n",
    "    time_init = time()\n",
    "    best = [{\"E\" : -np.inf, \"tau\": -np.inf, \"E_x\": -np.inf, \"tau_x\": -np.inf, \"sample_delay\": -np.inf} for i in range(signals_df.shape[0])]\n",
    "    for i in range(iteracoes):\n",
    "        # Cálculo de Fitness e inserção no dataframe\n",
    "        x_params = [{\"E\": candidato[0],\n",
    "                     \"tau\": candidato[1],\n",
    "                     \"E_x\": candidato[2],\n",
    "                     \"tau_x\": candidato[3],\n",
    "                     \"sample_delay\": candidato[4]} for candidato in x_pop]\n",
    "        mse_matrix = -funcao(signals_df, x_params, populacao)\n",
    "        x_fitness = np.sum(mse_matrix, axis=0).reshape(-1, 1)\n",
    "        iter_atual = np.tile([i], x_matrix.shape[0]).reshape(-1, 1)\n",
    "        df_data = np.concatenate((x_pop, x_fitness, iter_atual), axis=1)\n",
    "        df_evolution = pd.concat([df_evolution, pd.DataFrame(df_data, columns=col)]).reset_index(drop=True)\n",
    "        # Captura de fitness médio e fitness mínimo por iteração\n",
    "        avg_fitness = np.append(avg_fitness, np.mean(x_fitness))\n",
    "        min_fitness = np.append(min_fitness, np.min(x_fitness))\n",
    "        # Sorting Crescente\n",
    "        best = [{\"E\" : x_pop[np.argmax(mse_matrix[i]), 0],\n",
    "                \"tau\": x_pop[np.argmax(mse_matrix[i]), 1],\n",
    "                \"E_x\": x_pop[np.argmax(mse_matrix[i]), 2],\n",
    "                \"tau_x\": x_pop[np.argmax(mse_matrix[i]), 3],\n",
    "                \"sample_delay\": x_pop[np.argmax(mse_matrix[i]), 4]} for i in range(signals_df.shape[0])]\n",
    "        x_sort = np.argsort(x_fitness, axis=0).reshape(-1)\n",
    "        x_fitness = x_fitness[x_sort]\n",
    "        x_pop = x_pop[x_sort]\n",
    "        # Cálculo de probabilidades de seleção\n",
    "        prob_num = np.array([np.sum(np.arange(1, i+1)) for i in range(1, x_matrix.shape[0]+1)])\n",
    "        prob_den = np.sum(np.arange(1, x_fitness.shape[0]+1))\n",
    "        prob = prob_num/prob_den\n",
    "        # Seleção de elementos\n",
    "        selecao_prob = np.random.rand(np.ceil(x_fitness.shape[0]/2).astype(np.int32), 2)\n",
    "        index_selecao_prob = np.searchsorted(prob, selecao_prob, side='right')\n",
    "        # Recombinação\n",
    "        new_pop = np.empty((0, x_pop.shape[1]))\n",
    "        for j in index_selecao_prob:\n",
    "            candidato1 = x_pop[j[0]]\n",
    "            candidato2 = x_pop[j[1]]\n",
    "            recomb_mask = np.random.rand(candidato1.shape[0])\n",
    "            recomb_mask = np.array([p <= p_recomb for p in recomb_mask])\n",
    "            novo_candidato1 = np.copy(candidato1)\n",
    "            np.putmask(novo_candidato1, recomb_mask, candidato2)\n",
    "            novo_candidato1 = novo_candidato1.reshape((1, -1))\n",
    "            novo_candidato2 = np.copy(candidato2)\n",
    "            np.putmask(novo_candidato2, recomb_mask, candidato1)\n",
    "            novo_candidato2 = novo_candidato2.reshape((1, -1))\n",
    "            new_pop = np.concatenate((new_pop, novo_candidato1, novo_candidato2), axis=0)\n",
    "        new_pop = new_pop[:x_pop.shape[0]]\n",
    "        # Mutação\n",
    "        E_init = np.abs(np.random.normal(loc=90000, scale=80000, size=populacao))\n",
    "        tau_init = np.abs(np.random.normal(loc=60, scale=10, size=populacao))\n",
    "        E_x_init = np.abs(np.random.normal(loc=9000, scale=8000, size=populacao))\n",
    "        tau_x_init = np.abs(np.random.normal(loc=60, scale=10, size=populacao))\n",
    "        samp_delay_init = np.abs(np.random.normal(loc=3, scale=4, size=populacao))\n",
    "        mut_gen = np.stack([E_init, tau_init, E_x_init, tau_x_init, samp_delay_init], axis=1)\n",
    "        mut_mask = np.random.rand(new_pop.shape[0], new_pop.shape[1])\n",
    "        mut_mask = np.array([p <= p_mutacao for p in mut_mask])\n",
    "        np.putmask(new_pop, mut_mask, mut_gen)\n",
    "        # Nova População\n",
    "        x_pop = np.copy(new_pop)\n",
    "        if(i == iteracoes - 1):\n",
    "             # Cálculo de Fitness e inserção no dataframe\n",
    "            x_params = [{\"E\": candidato[0],\n",
    "                         \"tau\": candidato[1],\n",
    "                         \"E_x\": candidato[2],\n",
    "                         \"tau_x\": candidato[3],\n",
    "                         \"sample_delay\": candidato[4]} for candidato in x_pop]\n",
    "            mse_matrix = -funcao(signals_df, x_params, populacao)\n",
    "            x_fitness = np.sum(mse_matrix, axis=0).reshape(-1, 1)\n",
    "            iter_atual = np.tile([i], x_matrix.shape[0]).reshape(-1, 1)\n",
    "            df_data = np.concatenate((x_pop, x_fitness, iter_atual), axis=1)\n",
    "            df_evolution = pd.concat([df_evolution, pd.DataFrame(df_data, columns=col)]).reset_index(drop=True)\n",
    "            # Captura de fitness médio e fitness mínimo por iteração\n",
    "            avg_fitness = np.append(avg_fitness, np.mean(x_fitness))\n",
    "            min_fitness = np.append(min_fitness, np.min(x_fitness))\n",
    "\n",
    "    elapsed_time = (time() - time_init) * 1000\n",
    "    fitness_metrics = np.concatenate(([avg_fitness], [min_fitness]), axis = 0).transpose()\n",
    "    df_fitness = pd.DataFrame(fitness_metrics)\n",
    "    #df_fitness['Aptidao'] = ['Media', 'Minima']\n",
    "        \n",
    "    return best, df_evolution, df_fitness, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best, df_evolution, df_fitness, elapsed_time = genetico(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evolution[\"Gerações\"] = df_evolution[\"iter\"]\n",
    "df_evolution[\"Aptidão\"] = df_evolution[\"fitness\"]\n",
    "sns.lineplot(df_evolution, x='Gerações', y='Aptidão')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fitness_paralelo.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_index=10\n",
    "df_est_comparison = pd.DataFrame(data=[[\"E\", best[signal_index][\"E\"], df[\"E\"][signal_index]],\n",
    "                                 [\"Tau\", best[signal_index][\"tau\"], df[\"tau\"][signal_index]],\n",
    "                                 [\"E_x\", best[signal_index][\"E_x\"], df[\"E_x\"][signal_index]],\n",
    "                                 [\"Tau_x\", best[signal_index][\"tau_x\"], df[\"tau_x\"][signal_index]],\n",
    "                                 [\"Sampling Delay\", best[signal_index][\"sample_delay\"], df[\"delay_sampling\"][signal_index]]],\n",
    "                                 columns=[\"Parâmetro\", \"Estimado\", \"Esperado\"])\n",
    "\n",
    "df_est_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([df[\"delay_sampling\"][signal_index] + (25*i) for i in range(1, 5)],\n",
    "         [df[f\"S_{i}\"][signal_index] for i in range(1, 5)], marker='o', label=\"Samples\")\n",
    "\n",
    "ETrue_est = np.array([best[signal_index][\"E\"]*cellFunction(t*46.74/best[signal_index][\"tau\"]) for t in range(600)])\n",
    "XT_est = np.array([best[signal_index][\"E_x\"]*XTalk(t*32.16/best[signal_index][\"tau_x\"]) for t in range(600)])\n",
    "signal_est = ETrue_est + XT_est\n",
    "\n",
    "ETrue_gt = np.array([df[\"E\"][signal_index]*cellFunction(t*46.74/df[\"tau\"][signal_index]) for t in range(600)])\n",
    "XT_gt = np.array([df[\"E_x\"][signal_index]*XTalk(t*32.16/df[\"tau_x\"][signal_index]) for t in range(600)])\n",
    "signal_gt = ETrue_gt + XT_gt\n",
    "\n",
    "#Gráfico Comparativo\n",
    "plt.plot(range(600), signal_est, label=\"Signal with estimated parameters\")\n",
    "plt.plot(range(600), signal_gt, label=\"Ground Truth Signal\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_index=10\n",
    "\n",
    "E_diff = pd.DataFrame(np.array([(best[i][\"E\"] - df[\"E\"][i]) for i in range(df.shape[0])]))\n",
    "tau_diff = pd.DataFrame(np.array([(best[i][\"tau\"] - df[\"tau\"][i]) for i in range(df.shape[0])]))\n",
    "E_x_diff = pd.DataFrame(np.array([(best[i][\"E_x\"] - df[\"E_x\"][i]) for i in range(df.shape[0])]))\n",
    "tau_x_diff = pd.DataFrame(np.array([(best[i][\"tau_x\"] - df[\"tau_x\"][i]) for i in range(df.shape[0])]))\n",
    "sample_delay_diff = pd.DataFrame(np.array([(best[i][\"sample_delay\"] - df[\"delay_sampling\"][i]) for i in range(df.shape[0])]))\n",
    "\n",
    "E_diff[\"Param\"] = \"E\"\n",
    "tau_diff[\"Param\"] = \"tau\"\n",
    "E_x_diff[\"Param\"] = \"E_x\"\n",
    "tau_x_diff[\"Param\"] = \"tau_x\"\n",
    "sample_delay_diff[\"Param\"] = \"sampling_delay\"\n",
    "\n",
    "df_comparison = pd.concat([E_diff, E_x_diff, tau_diff, tau_x_diff, sample_delay_diff])\n",
    "df_comparison[\"Erro\"] = df_comparison[0]\n",
    "df_comparison[\"Parâmetro\"] = df_comparison[\"Param\"]\n",
    "df_comparison.groupby(\"Parâmetro\")[\"Erro\"].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison.groupby(\"Parâmetro\")[\"Erro\"].agg([\"mean\", \"std\"]).to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = pd.concat([E_diff, E_x_diff])\n",
    "df_diff\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 6))\n",
    "sns.boxplot(data=df_diff, x=0, y=\"Param\", ax=ax[0], hue=\"Param\")\n",
    "\n",
    "#ax[0].set_title(\"Erro de estimação de energia - Otimização Paralela\")\n",
    "ax[0].set_xlabel(\"Energia (MeV)\")\n",
    "ax[0].set_ylabel(None)\n",
    "ax[0].set_yticklabels([\"E\", f\"${{E_x}}$\"])\n",
    "\n",
    "df_diff = pd.concat([tau_diff, tau_x_diff, sample_delay_diff])\n",
    "df_diff\n",
    "\n",
    "sns.boxplot(data=df_diff, x=0, y=\"Param\", ax=ax[1], hue=\"Param\")\n",
    "#ax[1].set_title(\"Erro de estimação de tempo - Otimização Paralela\")\n",
    "ax[1].set_xlabel(\"Tempo (ns)\")\n",
    "ax[1].set_ylabel(None)\n",
    "ax[1].set_yticklabels([r'$\\tau$', r'$\\tau_x$', \"sample_delay\"])\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"boxplot_paralelo.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(df.shape[0]):\n",
    "    plt.plot([df[\"delay_sampling\"][k] + (25*i) for i in range(1, 5)],\n",
    "            [df[f\"S_{i}\"][k] for i in range(1, 5)], marker='o', label=\"Samples\")\n",
    "\n",
    "    ETrue_est = np.array([best[k][\"E\"]*cellFunction(t*46.74/best[k][\"tau\"]) for t in range(600)])\n",
    "    XT_est = np.array([best[k][\"E_x\"]*XTalk(t*32.16/best[k][\"tau_x\"]) for t in range(600)])\n",
    "    signal_est = ETrue_est + XT_est\n",
    "\n",
    "    ETrue_gt = np.array([df[\"E\"][k]*cellFunction(t*46.74/df[\"tau\"][k]) for t in range(600)])\n",
    "    XT_gt = np.array([df[\"E_x\"][k]*XTalk(t*32.16/df[\"tau_x\"][k]) for t in range(600)])\n",
    "    signal_gt = ETrue_gt + XT_gt\n",
    "\n",
    "    #Gráfico Comparativo\n",
    "    plt.plot(range(600), signal_est, label=\"Signal with estimated parameters\")\n",
    "    plt.plot(range(600), signal_gt, label=\"Ground Truth Signal\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
